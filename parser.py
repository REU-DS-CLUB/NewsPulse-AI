# -*- coding: utf-8 -*-
"""parser.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vL-Ig4vu5GwLfbiNVnEIBN6isY3rZffm
"""

import requests
from bs4 import BeautifulSoup
from time import sleep
import csv
from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup
from time import sleep
import csv
from urllib.parse import urljoin

def get_url(parser_dict:dict, url:str):
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/117.0.0.0 Safari/537.36"
        ),
        "Accept-Language": "ru,en;q=0.9",
    }
    response=requests.get(url,headers)

    soup=BeautifulSoup(response.text,'lxml')
    general_data=soup.find_all('a',class_='card-full-news _parts-news')

    for data in general_data:
        sleep(1)
        name=data.find('h3',class_='card-full-news__title').text
        parser_dict[name] = urljoin("https://lenta.ru", data.get("href"))

    add_data=soup.find('a',class_='loadmore js-loadmore')

    if add_data:
        add_url = urljoin('https://lenta.ru',add_data.get('href') )
        return get_url(parser_dict,add_url)
    else:
        return parser_dict

url='https://lenta.ru/parts/news/'
parser_dict=get_url(dict(), url)

def get_text(parser_dict: dict):
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/117.0.0.0 Safari/537.36"
        ),
        "Accept-Language": "ru,en;q=0.9",
    }

    bad_url=0
    for title,url in parser_dict.items():

        response = requests.get(url, headers)
        soup = BeautifulSoup(response.text, 'lxml')

        general_data=soup.find('div',class_='topic-page__container')
        try:
          all_texts=general_data.find_all('p',class_='topic-body__content-text')
        except Exception as e:
          bad_url+=1
          print(url)
          continue

        text=' '.join(p.get_text() for p in all_texts )
        with open("parser.csv", "a", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=["title", "text"])
            if f.tell() == 0:
                writer.writeheader()
            writer.writerow({"title": title, "text": text})
    print('Done!')

get_text(parser_dict)

